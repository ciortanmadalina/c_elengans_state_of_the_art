{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # this adds to path parent directory in order to import utils file\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from IPython.display import clear_output, Image, display\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import igraph as ig\n",
    "import louvain\n",
    "import time\n",
    "import pickle\n",
    "import umap\n",
    "## Import custom utils\n",
    "import gmm_utils\n",
    "import hyperopt_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "elbowAnalysis\n",
      "silhouetteAnalyis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'hyperopt_utils' from '../hyperopt_utils.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import importlib\n",
    "importlib.reload(gmm_utils)\n",
    "importlib.reload(hyperopt_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 22085) (420, 2) [3 4 1 6 2 7 5 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dataset': 'brainCIDR',\n",
       "  'doUmap': True,\n",
       "  'log': True,\n",
       "  'minCellsPerGene': 0,\n",
       "  'minGeneDispersion': 0,\n",
       "  'nb_neighbors': 10,\n",
       "  'pca_comp': 10,\n",
       "  'randIndex': 0.3896711401407734,\n",
       "  'scaler': 'standardScaleCells',\n",
       "  'umap_comp': 3},\n",
       " array([ 3,  1, 10, 10,  3,  1,  3, 10, 10,  3, 10,  3,  8,  3,  1,  3,  1,\n",
       "         1,  4,  1,  4,  4,  3,  3,  4,  3,  3,  3,  3,  4, 10,  3,  3,  3,\n",
       "         1, 10,  3,  3, 10, 10,  8, 10,  4,  1,  3,  3,  3,  4,  1,  1,  4,\n",
       "         3,  3,  4,  1,  4,  4,  3,  1,  3,  4,  1, 10,  1, 10, 10,  1,  4,\n",
       "         1,  4,  3,  4, 10,  1,  4,  4, 10,  1,  4, 10,  3,  4,  4,  1,  3,\n",
       "         4,  1,  4,  1, 10,  2,  2,  0, 13, 13, 11, 16, 11, 11,  0,  0, 16,\n",
       "         6, 13, 16,  0,  7,  0,  6, 13,  7, 16,  0, 15,  6,  0,  0, 13, 17,\n",
       "        17, 13, 12, 12, 13, 17,  7, 17,  5,  0, 12,  5,  7, 17,  7, 13, 17,\n",
       "         8,  8,  1,  8,  8,  8,  8,  8,  8,  1,  8,  8,  8,  8,  1,  8,  8,\n",
       "         8,  1,  8,  1,  8,  1,  1,  1,  8,  4,  1,  4,  1,  4,  1, 10,  1,\n",
       "         4,  3,  3,  4,  4,  8,  4, 10, 10,  3, 15, 15,  9,  5,  0,  7, 17,\n",
       "        11, 12, 11, 12, 12, 17, 12, 17,  5,  0,  1, 11,  0,  2,  2,  0,  2,\n",
       "         0,  0, 13,  2,  6,  2,  2,  5,  2,  2,  2,  2, 16,  0,  0,  9,  0,\n",
       "         5,  7,  0, 16,  5,  2,  2,  9,  2,  2, 13,  2,  0,  2,  2,  5,  2,\n",
       "         9,  2,  2,  2,  5, 16,  2, 13,  2,  2,  2,  2,  2,  2,  2,  6, 11,\n",
       "         0, 16, 11,  6, 11,  7, 11,  6, 11, 11,  0,  0, 11,  0,  7,  0,  0,\n",
       "         0,  7, 11,  0,  0, 11,  7,  7,  7, 12, 11,  6,  6,  6,  0, 11,  6,\n",
       "         6,  6, 11,  0,  7,  0,  6,  9,  6,  0,  9,  5,  0,  7,  7,  6,  0,\n",
       "         2,  9,  0,  0,  0,  0,  9,  9,  9,  9,  9,  6,  0,  0,  0,  6,  0,\n",
       "         6,  6, 15,  6, 14, 17, 15, 15, 15,  6, 14, 15,  7, 15, 15, 15, 15,\n",
       "        12, 14, 14, 14, 14, 12, 12, 14, 14, 14, 14, 14, 14, 14, 12, 12, 14,\n",
       "        14, 15, 12, 12, 12, 12, 14,  0,  7, 13,  5, 12,  9, 16,  2,  5,  0,\n",
       "         5,  7,  9,  6,  9,  0,  5,  0,  9,  5,  0,  7,  9,  9,  0, 16,  0,\n",
       "         5, 16,  5, 16,  0,  5, 13,  0,  0,  5, 13,  5, 16, 11,  9,  7, 13,\n",
       "         5,  0,  5, 13,  7, 13,  0,  9,  5,  9,  0,  0]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'brainCIDR'\n",
    "df, truth = gmm_utils.loadData(dataset)\n",
    "\n",
    "print(df.shape, truth.shape, truth.clusters.unique())\n",
    "params={}\n",
    "params['dataset'] = 'brainCIDR'\n",
    "params['minCellsPerGene'] = 0\n",
    "params['minGeneDispersion'] = 0\n",
    "params['log'] = True # True, False\n",
    "params['scaler'] = 'standardScaleCells'# \n",
    "params['pca_comp'] = 10 #range (3, 300)\n",
    "params['doUmap'] = True #range (3, 300)\n",
    "params['umap_comp'] = 3\n",
    "params['nb_neighbors'] =10 #3 -15\n",
    "gmm_utils.runLouvain(params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def runHyperopt(filename, space, max_evals = 2, restart = False):\n",
    "    # Define function to optimise\n",
    "    def evaluateLouvain(args):\n",
    "        try:\n",
    "            resultDict, _ = gmm_utils.runLouvain(args)\n",
    "        except:\n",
    "            return { 'status' : hyperopt.STATUS_FAIL}\n",
    "\n",
    "        print(f'>> Result: {resultDict[\"randIndex\"]}')\n",
    "        ret = {\n",
    "            'loss' : -resultDict['randIndex']\n",
    "            ,'status' : STATUS_OK\n",
    "            ,'eval_time' : time.time()        \n",
    "        }\n",
    "        return ret\n",
    "\n",
    "    trials = hyperopt_utils.getTrials(filename ,restart = restart )\n",
    "    evals_per_epoch = 10\n",
    "    for e in range(len(trials), max_evals, evals_per_epoch):\n",
    "        best = fmin(evaluateLouvain\n",
    "                    ,space\n",
    "                    ,algo=tpe.suggest \n",
    "                    ,max_evals= e + evals_per_epoch\n",
    "                    ,trials=trials)\n",
    "        print('Index ', e)\n",
    "        pickle.dump(trials, open(filename, 'wb'))\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain CIDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'brainCIDR'\n",
    "space = {\n",
    "    'dataset' : dataset\n",
    "    ,'minCellsPerGene':scope.int(hp.quniform('minCellsPerGene', 0, 5, 1))\n",
    "    ,'minGeneDispersion':hp.uniform('minGeneDispersion', 0, 1.5)\n",
    "    ,'log' : hp.choice('log', [True,False])\n",
    "    ,'scaler' : hp.choice('scaler',\n",
    "            ['none','standardScaleGenes', 'standardScaleCells', 'robustScaleGenes', 'robustScaleCells'])\n",
    "    ,'pca_comp' : scope.int(hp.quniform('pca_comp', 5, 300,1))\n",
    "    ,'doUmap' : hp.choice('doUmap', [True,False])\n",
    "    ,'umap_comp' : scope.int(hp.quniform('umap_comp', 2, 5,1))\n",
    "    ,'nb_neighbors' : scope.int(hp.quniform('nb_neighbors', 6, 30, 1))\n",
    "}\n",
    "\n",
    "filename = f'{dataset}_louvain_trials.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new trials...\n"
     ]
    }
   ],
   "source": [
    "trials=hyperopt_utils.getTrials(filename ,restart = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new trials...\n",
      ">> Result: 0.3823085687972271\n",
      ">> Result: 0.26569598332185074\n",
      ">> Result: 0.42681363257444055\n",
      ">> Result: 0.41937512893833306\n",
      ">> Result: 0.5682008392900804\n",
      ">> Result: 0.35089113970218055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.6435556351100351\n",
      ">> Result: 0.3233628764992152\n",
      ">> Result: 0.45479620648895835\n",
      ">> Result: 0.527020448578572\n",
      "Index  0\n",
      ">> Result: 0.44317862756972254\n",
      ">> Result: 0.39861367397288233\n",
      ">> Result: 0.3892968675720729\n",
      ">> Result: 0.37831073005945337\n",
      ">> Result: 0.4961602750698821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.7596723111604312\n",
      ">> Result: 0.5483240288797667\n",
      ">> Result: 0.34335539098249956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.5086045909774787\n",
      ">> Result: 0.3890820198734051\n",
      "Index  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.6344212618029101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.6983109438612145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.7012275715185803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.7189609460278771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.6972647834302852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.676737089526265\n",
      ">> Result: 0.648476921354741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.7221909444707502\n",
      ">> Result: 0.550911150634164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.6150012753912408\n",
      "Index  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.5362954117394108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.68477249434332\n",
      ">> Result: 0.4826934430976177\n",
      ">> Result: 0.6010526546557816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.6834006949993392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.5212688739614642\n",
      ">> Result: 0.4440049332290721\n",
      ">> Result: 0.6013424906468426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.7246914179406098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.7268063371751615\n",
      "Index  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.6751047562493977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.7003167958971882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.650408129666742\n",
      ">> Result: 0.36656523379605854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.6249971110683609\n",
      ">> Result: 0.4982147821762358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.7061152510024388\n",
      ">> Result: 0.41564152058048637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.44335498455267275\n",
      ">> Result: 0.3343167211708708\n",
      "Index  40\n",
      ">> Result: 0.400445782594324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.7579557813818834\n",
      ">> Result: 0.7535573945030459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.4657092140259908\n",
      ">> Result: 0.5716164153090045\n",
      ">> Result: 0.45579640752711104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.42895525416885555\n",
      ">> Result: 0.5561800447890313\n",
      ">> Result: 0.4722103022514341\n",
      ">> Result: 0.6935120456289303\n",
      "Index  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.47351558085713386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.5490597992742366\n",
      ">> Result: 0.5853219546839146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Result: 0.7308323089666864\n",
      ">> Result: 0.3891154409580249\n",
      ">> Result: 0.7643200271042186\n",
      ">> Result: 0.7493201642890226\n",
      ">> Result: 0.6602662794678176\n",
      ">> Result: 0.570075995461746\n",
      ">> Result: 0.5440569319691174\n",
      "Index  60\n",
      ">> Result: 0.4407932202106022\n",
      ">> Result: 0.7836092125332547\n",
      ">> Result: 0.6715425064973602\n",
      ">> Result: 0.676404312700071\n",
      ">> Result: 0.7890512703035873\n",
      ">> Result: 0.5518334532818321\n",
      ">> Result: 0.6695364164156907\n",
      ">> Result: 0.6879806555422511\n",
      ">> Result: 0.770109012292583\n",
      ">> Result: 0.7801644359143579\n",
      "Index  70\n",
      ">> Result: 0.8413495159018819\n",
      ">> Result: 0.67367144760814\n",
      ">> Result: 0.7876663083099568\n",
      ">> Result: 0.46523660525485255\n",
      ">> Result: 0.5174730646445744\n",
      ">> Result: 0.7919127987354188\n",
      ">> Result: 0.5680880528552832\n",
      ">> Result: 0.5303652658573142\n",
      ">> Result: 0.7512775297348602\n",
      ">> Result: 0.7901441510891695\n",
      "Index  80\n",
      ">> Result: 0.7680808878055183\n",
      ">> Result: 0.7588220005031866\n",
      ">> Result: 0.4267262887300326\n",
      ">> Result: 0.7368367805963439\n",
      ">> Result: 0.6645374004605826\n",
      ">> Result: 0.49859813417917026\n",
      ">> Result: 0.39259709255859987\n",
      ">> Result: 0.7015151881173107\n",
      ">> Result: 0.7668591051117514\n",
      ">> Result: 0.6965515296771465\n",
      "Index  90\n",
      ">> Result: 0.7842007664678865\n",
      ">> Result: 0.5238301948819699\n",
      ">> Result: 0.6498732923650445\n",
      ">> Result: 0.7600409060524769\n",
      ">> Result: 0.680855734448772\n",
      ">> Result: 0.7795935857951063\n",
      ">> Result: 0.5352089933516128\n",
      ">> Result: 0.46783662770190376\n",
      ">> Result: 0.7580421705639746\n",
      ">> Result: 0.6938242045613435\n",
      "Index  100\n",
      ">> Result: 0.7769197633794629\n",
      ">> Result: 0.3673890894871268\n",
      ">> Result: 0.6663538705278704\n",
      ">> Result: 0.6798067972655498\n",
      ">> Result: 0.6771137379587766\n",
      ">> Result: 0.6183499981608341\n",
      ">> Result: 0.502637635541099\n",
      ">> Result: 0.7886846324490081\n",
      ">> Result: 0.7977505607855513\n",
      ">> Result: 0.5640987480015331\n",
      "Index  110\n",
      ">> Result: 0.8146574821540099\n",
      ">> Result: 0.8355538610730435\n",
      ">> Result: 0.49701594209504374\n",
      ">> Result: 0.7912157040121761\n",
      ">> Result: 0.8091015450469946\n",
      ">> Result: 0.8595436473815479\n",
      ">> Result: 0.8991321062448879\n",
      ">> Result: 0.38730972471014163\n",
      ">> Result: 0.5207977940064308\n"
     ]
    }
   ],
   "source": [
    "trials = runHyperopt(filename, space, max_evals = 500, restart = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDf = hyperopt_utils.getResultsAsDf(trials, space)\n",
    "summaryDf.sort_values(by='result', ascending =True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDf.to_pickle(f'{dataset}_louvain_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDf = pd.read_pickle(f'{dataset}_louvain_df.pkl')\n",
    "gmm_utils.plotBestPrediction(summaryDf, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PancreaticIsletCIDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= 'pancreaticIsletCIDR'\n",
    "df, truth = gmm_utils.loadData(dataset)\n",
    "print(df.shape, truth.shape, truth.clusters.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space = {\n",
    "    'dataset' : dataset\n",
    "    ,'minCellsPerGene':scope.int(hp.quniform('minCellsPerGene', 0, 5, 1))\n",
    "    ,'minGeneDispersion':hp.uniform('minGeneDispersion', 0, 1.5)\n",
    "    ,'log' : hp.choice('log', [True,False])\n",
    "    ,'scaler' : hp.choice('scaler',\n",
    "            ['none','standardScaleGenes', 'standardScaleCells', 'robustScaleGenes', 'robustScaleCells'])\n",
    "    ,'pca_comp' : scope.int(hp.quniform('pca_comp', 5, 300,1))\n",
    "    ,'doUmap' : hp.choice('doUmap', [True,False])\n",
    "    ,'umap_comp' : scope.int(hp.quniform('umap_comp', 2, 5,1))\n",
    "    ,'nb_neighbors' : scope.int(hp.quniform('nb_neighbors', 6, 30, 1))\n",
    "}\n",
    "\n",
    "filename = f'{dataset}_louvain_trials.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials=hyperopt_utils.getTrials(filename ,restart = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = runHyperopt(filename, space, max_evals = 500, restart = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDf = hyperopt_utils.getResultsAsDf(trials, space)\n",
    "summaryDf.sort_values(by='result', ascending =True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDf.to_pickle(f'{dataset}_louvain_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDf = pd.read_pickle(f'{dataset}_louvain_df.pkl')\n",
    "gmm_utils.plotBestPrediction(summaryDf, dataset, pca_comp = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= 'deng'\n",
    "df, truth = gmm_utils.loadData(dataset)\n",
    "umap2D = gmm_utils.getUmap(df, pca_comp = 10)\n",
    "print(df.shape, truth.shape, truth.clusters.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space = {\n",
    "    'dataset' : dataset\n",
    "    ,'minCellsPerGene':scope.int(hp.quniform('minCellsPerGene', 0, 5, 1))\n",
    "    ,'minGeneDispersion':hp.uniform('minGeneDispersion', 0, 1.5)\n",
    "    ,'log' : hp.choice('log', [True,False])\n",
    "    ,'scaler' : hp.choice('scaler',\n",
    "            ['none','standardScaleGenes', 'standardScaleCells', 'robustScaleGenes', 'robustScaleCells'])\n",
    "    ,'pca_comp' : scope.int(hp.quniform('pca_comp', 5, 300,1))\n",
    "    ,'doUmap' : hp.choice('doUmap', [True,False])\n",
    "    ,'umap_comp' : scope.int(hp.quniform('umap_comp', 2, 5,1))\n",
    "    ,'nb_neighbors' : scope.int(hp.quniform('nb_neighbors', 6, 30, 1))\n",
    "}\n",
    "\n",
    "filename = f'{dataset}_louvain_trials.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials=hyperopt_utils.getTrials(filename ,restart = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = runHyperopt(filename, space, max_evals = 500, restart = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDf = hyperopt_utils.getResultsAsDf(trials, space)\n",
    "summaryDf.sort_values(by='result', ascending =True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDf.to_pickle(f'{dataset}_louvain_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDf = pd.read_pickle(f'{dataset}_louvain_df.pkl')\n",
    "gmm_utils.plotBestPrediction(summaryDf, dataset, pca_comp = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestBic, bestAic, bestSil = optimalNbClustersGMM(pc, params['min_clusters'], params['max_clusters'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestBic, bestAic, bestSil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_clust in n_clusters:\n",
    "    model = GaussianMixture(n_clust, covariance_type ='full', random_state = 0).fit(pc)\n",
    "    clusters = model.predict(pc)\n",
    "    score = adjusted_rand_score(truth.clusters.tolist(), clusters)\n",
    "    print(f\"For {n_clust} clusters, score : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianMixture(8, covariance_type ='full', random_state = 0).fit(pc)\n",
    "clusters = model.predict(pc)\n",
    "score = adjusted_rand_score(truth.clusters.tolist(), clusters)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth.clusters.value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'brainCIDR'\n",
    "df, truth = gmm_utils.loadData(dataset)\n",
    "umap2D = gmm_utils.getUmap(df, pca_comp = 10)\n",
    "print(df.shape, truth.shape, truth.clusters.unique())\n",
    "params={}\n",
    "params['dataset'] = 'brainCIDR'\n",
    "params['minCellsPerGene'] = 0\n",
    "params['minGeneDispersion'] = 0\n",
    "params['log'] = True # True, False\n",
    "params['scaler'] = 'standardScaleCells'# \n",
    "params['pca_comp'] = 10 #range (3, 300)\n",
    "params['nb_clusters'] =8 #3 -15\n",
    "gmm_utils.run(params);"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
