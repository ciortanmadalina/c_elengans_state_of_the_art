{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T14:24:46.758911Z",
     "start_time": "2018-12-25T14:24:00.671879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbowAnalysis\n",
      "silhouetteAnalyis\n",
      "elbowAnalysis\n",
      "silhouetteAnalyis\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # this adds to path parent directory in order to import utils file\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from IPython.display import clear_output, Image, display\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import igraph as ig\n",
    "import louvain\n",
    "import time\n",
    "import pickle\n",
    "import umap\n",
    "import os\n",
    "import traceback\n",
    "## Import custom utils\n",
    "import utils\n",
    "import gmm_utils\n",
    "import hyperopt_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T14:24:47.362776Z",
     "start_time": "2018-12-25T14:24:46.853409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbowAnalysis\n",
      "silhouetteAnalyis\n",
      "elbowAnalysis\n",
      "silhouetteAnalyis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'hyperopt_utils' from '..\\\\hyperopt_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import importlib\n",
    "importlib.reload(gmm_utils)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(hyperopt_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T14:24:49.507040Z",
     "start_time": "2018-12-25T14:24:47.406125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check run louvain method\n",
    "dataset = 'brainCIDR'\n",
    "df, truth = utils.loadData(dataset)\n",
    "y = truth.clusters\n",
    "\n",
    "params={}\n",
    "params['dataset'] = 'brainCIDR'\n",
    "params['minCellsPerGene'] = 0\n",
    "params['minGeneDispersion'] = 0\n",
    "params['log'] = True # True, False\n",
    "params['scaler'] = 'standardScaleCells'# \n",
    "params['pca_comp'] = 10 #range (3, 300)\n",
    "params['doUmap'] = False #range (3, 300)\n",
    "params['umap_comp'] = 3\n",
    "params['nb_neighbors'] =10 #3 -15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T14:24:52.036781Z",
     "start_time": "2018-12-25T14:24:52.012993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.dataset = dataset\n",
      "self.minCellsPerGene = minCellsPerGene\n",
      "self.minGeneDispersion = minGeneDispersion\n",
      "self.log = log\n",
      "self.scaler = scaler\n",
      "self.pca_comp = pca_comp\n",
      "self.doUmap = doUmap\n",
      "self.umap_comp = umap_comp\n",
      "self.nb_neighbors = nb_neighbors\n"
     ]
    }
   ],
   "source": [
    "for k,v in params.items():\n",
    "    print(f'self.{k} = {k}', end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T14:26:07.096670Z",
     "start_time": "2018-12-25T14:26:06.268619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.nb_neighbors = 10\n",
      "fit (420, 22085)\n",
      "predict (420, 22085), bla\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3,  5,  5,  8,  8,  5,  8,  5,  3,  3,  8,  5,  0,  5,  9,  5,  5,\n",
       "        5,  8,  5,  3,  8,  8,  8,  8,  5,  8,  3,  3,  3,  3,  5,  8,  3,\n",
       "        9,  8,  8,  5,  5,  5,  2,  8,  3,  5,  3,  5,  5,  8,  8,  0,  8,\n",
       "        5,  5,  3,  9,  5,  3,  8,  9,  3,  8,  0,  3,  5,  3,  3,  5,  3,\n",
       "        9,  8,  8,  5,  8,  0,  3,  5,  8,  9,  8,  8,  3,  9,  9,  2,  2,\n",
       "        3,  9,  8,  0,  8, 10, 10,  2,  6, 10,  1,  9,  4,  0,  9,  5,  2,\n",
       "        4, 10,  2,  2,  2,  9,  4,  6,  7,  7,  2,  4,  4,  9,  2,  6,  0,\n",
       "        0,  1,  0,  0,  6,  0,  1,  6,  0,  0,  1,  0,  0,  6,  0,  6,  6,\n",
       "        2,  2,  9,  2,  8,  7,  9,  9,  2,  3,  2,  2,  3,  7,  9,  2,  2,\n",
       "        5,  2,  5,  5,  2,  9,  2,  8,  5,  3,  5,  3,  5,  5,  5,  3,  2,\n",
       "        3,  8,  5,  3,  8,  9,  3,  9,  5,  5,  4,  4,  1,  0,  7,  1,  0,\n",
       "        1,  1,  0,  0,  0,  1,  1,  1,  0,  2,  0,  0,  0, 10,  6,  3,  6,\n",
       "        5,  3, 10,  6,  4, 10,  6,  1,  6,  6, 10,  6,  3,  3,  3,  1,  3,\n",
       "        1,  1,  2,  3,  1, 10,  6,  1,  6,  6,  6,  6,  2,  6,  6,  1,  6,\n",
       "        7, 10,  6,  6,  6,  2,  6, 10,  6,  6,  6,  6, 10,  6, 10,  4,  1,\n",
       "        2,  7,  1,  4,  1,  1,  1,  4,  1,  0,  1,  9,  1,  7,  7,  2,  9,\n",
       "        7,  7,  4,  7,  2,  4,  2,  7,  7,  0,  0,  4,  4,  4,  9,  0,  4,\n",
       "        4,  4,  1,  7,  0,  2,  4,  1,  4,  7,  1,  1,  2,  0,  0,  4,  2,\n",
       "        4,  7,  9,  0,  7,  2,  0,  7,  0,  1,  7,  4,  2,  4,  7,  4,  7,\n",
       "        4,  4,  4,  4,  7,  1,  4,  4,  4,  4,  7,  4,  7,  4,  4,  4,  4,\n",
       "        1,  0,  7,  1,  7,  1,  0,  0,  7,  1,  1,  1,  7,  2,  1,  0,  1,\n",
       "        1,  4,  1,  1,  1,  1,  7,  2,  1,  6,  1,  1,  2,  1,  6,  0,  0,\n",
       "        0,  1,  0,  0,  1,  3,  0,  0,  0,  0,  7,  0,  0,  0,  9,  9,  7,\n",
       "        0,  3,  0,  2,  2,  7, 10,  2,  3,  1, 10,  0,  2,  2,  7,  6,  6,\n",
       "        0,  2,  1, 10,  7, 10,  2,  0,  0,  1,  3,  3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LouvainModel(BaseEstimator):\n",
    "    def __init__(self,  \n",
    "                 minCellsPerGene=0, \n",
    "                 minGeneDispersion=0, \n",
    "                 log=True, \n",
    "                 scaler='standardScaleCells', \n",
    "                 pca_comp=10, \n",
    "                 doUmap=False, \n",
    "                 umap_comp=3, \n",
    "                 nb_neighbors=10):\n",
    "        self.minCellsPerGene = minCellsPerGene\n",
    "        self.minGeneDispersion = minGeneDispersion\n",
    "        self.log = log\n",
    "        self.scaler = scaler\n",
    "        self.pca_comp = pca_comp\n",
    "        self.doUmap = doUmap\n",
    "        self.umap_comp = umap_comp\n",
    "        self.nb_neighbors = nb_neighbors\n",
    "\n",
    "    def preprocess(df):\n",
    "        discreteDf = np.zeros(df.shape)\n",
    "        discreteDf[np.where(df>0)] = 1\n",
    "        genesToKeep = np.where(discreteDf.sum(axis = 0)>=self.minCellsPerGene )[0]\n",
    "        df= df[df.columns[genesToKeep]]\n",
    "        del discreteDf \n",
    "\n",
    "        # Remove genes which have a very low variance as they are expressed equally in all cells\n",
    "        logDf = np.log1p(df)\n",
    "        nonZeroMean = logDf.mean(axis = 0)\n",
    "        nonZeroMean[nonZeroMean==0] = 1e-10\n",
    "        dispersion =logDf.var(axis = 0)/nonZeroMean\n",
    "        genesToKeep = np.where(dispersion>=self.minGeneDispersion )[0]\n",
    "        df= df[df.columns[genesToKeep]]\n",
    "        del logDf, nonZeroMean, dispersion\n",
    "\n",
    "        if self.log:\n",
    "            df = np.log1p(df)\n",
    "\n",
    "        # scaling\n",
    "        if self.scaler == 'none':\n",
    "            scaledDf = df.values\n",
    "        if self.scaler == 'standardScaleGenes':\n",
    "            scaledDf = StandardScaler().fit_transform(df)\n",
    "        if self.scaler == 'standardScaleCells':\n",
    "            scaledDf = StandardScaler().fit_transform(df.T).T\n",
    "        if self.scaler == 'robustScaleGenes':\n",
    "            scaledDf = RobustScaler().fit_transform(df)\n",
    "        if self.scaler == 'robustScaleCells':\n",
    "            scaledDf = RobustScaler().fit_transform(df.T).T\n",
    "        return scaledDf\n",
    "    def fit(self, X, y):\n",
    "        X = self.preprocess(X)\n",
    "        # PCA reduction\n",
    "        self.pca= PCA(self.pca_comp)\n",
    "        self.pca.fit(X)\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        X = self.preprocess(X)\n",
    "        data = self.pca.transform(X)\n",
    "        if self.doUmap:\n",
    "            data = gmm_utils.getUmap(data, ncomp = self.umap_comp)\n",
    "        clusters = gmm_utils.cluster_knn_louvain(data, neighbors = self.nb_neighbors)\n",
    "        return clusters\n",
    "    \n",
    "    def fitPredict(self, X):\n",
    "        self.fit(X, None)\n",
    "        return self.predict(X)\n",
    "    \n",
    "    def scorer(self,clf, X, y_true):\n",
    "        print(f'scorer {X.shape}, {y_true.shape}')\n",
    "        from sklearn.metrics.cluster import adjusted_rand_score\n",
    "        y_pred = clf.predict(X)\n",
    "        return adjusted_rand_score(y_true, y_pred)\n",
    "        \n",
    "model = LouvainModel(params['dataset'], params)\n",
    "model.fitPredict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T14:26:18.329900Z",
     "start_time": "2018-12-25T14:26:17.159842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.nb_neighbors = 8\n",
      "self.nb_neighbors = 8\n",
      "fit (210, 22085)\n",
      "scorer (210, 22085), (210,)\n",
      "predict (210, 22085), bla\n",
      "self.nb_neighbors = 8\n",
      "fit (210, 22085)\n",
      "scorer (210, 22085), (210,)\n",
      "predict (210, 22085), bla\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.15086086, 0.29539015])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "model = LouvainModel(nb_neighbors=8)\n",
    "cross_val_score(model, df, y,\n",
    "                      scoring = model.my_scorer, \n",
    "                cv = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-23T20:51:00.356133Z",
     "start_time": "2018-12-23T20:51:00.350611Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-23T21:01:51.705237Z",
     "start_time": "2018-12-23T21:01:51.679619Z"
    }
   },
   "outputs": [],
   "source": [
    "def runLouvain(params):\n",
    "    df, truth = utils.loadData(params['dataset'])\n",
    "    y = truth.clusters.tolist()\n",
    "    idxTrain, idxTest, yTrain, yTest = train_test_split(np.arange(df.shape[0]), y, stratify = y, test_size = 0.2)\n",
    "    print(len(idxTrain), len(idxTest))\n",
    "    dfOrig = df.copy()\n",
    "    # Preprocessing remove genes which don't appear in at least minCellsPerGene cells\n",
    "    discreteDf = np.zeros(df.shape)\n",
    "    discreteDf[np.where(df>0)] = 1\n",
    "    genesToKeep = np.where(discreteDf.sum(axis = 0)>=params['minCellsPerGene'] )[0]\n",
    "    df= df[df.columns[genesToKeep]]\n",
    "    del discreteDf \n",
    "    \n",
    "    # Remove genes which have a very low variance as they are expressed equally in all cells\n",
    "    logDf = np.log1p(df)\n",
    "    nonZeroMean = logDf.mean(axis = 0)\n",
    "    nonZeroMean[nonZeroMean==0] = 1e-10\n",
    "    dispersion =logDf.var(axis = 0)/nonZeroMean\n",
    "    genesToKeep = np.where(dispersion>=params['minGeneDispersion'] )[0]\n",
    "    df= df[df.columns[genesToKeep]]\n",
    "    del logDf, nonZeroMean, dispersion\n",
    "\n",
    "    if params['log']:\n",
    "        df = np.log1p(df)\n",
    "        \n",
    "    # scaling\n",
    "    if params['scaler'] == 'none':\n",
    "        scaledDf = df.values\n",
    "    if params['scaler'] == 'standardScaleGenes':\n",
    "        scaledDf = StandardScaler().fit_transform(df)\n",
    "    if params['scaler'] == 'standardScaleCells':\n",
    "        scaledDf = StandardScaler().fit_transform(df.T).T\n",
    "    if params['scaler'] == 'robustScaleGenes':\n",
    "        scaledDf = RobustScaler().fit_transform(df)\n",
    "    if params['scaler'] == 'robustScaleCells':\n",
    "        scaledDf = RobustScaler().fit_transform(df.T).T\n",
    "        \n",
    "    # PCA reduction\n",
    "    pca= PCA(n_components=params['pca_comp'])\n",
    "    pca.fit(scaledDf[idxTrain])\n",
    "#     trainData = pca.transform(scaledDf[idxTrain])\n",
    "#     testData = pca.transform(scaledDf[idxTest])\n",
    "\n",
    "    data = pca.transform(scaledDf)\n",
    "#     data = PCA(n_components=params['pca_comp']).fit_transform(scaledDf)\n",
    "#     if params['doUmap']:\n",
    "#         data = gmm_utils.getUmap(data, ncomp = params['umap_comp'])\n",
    "    \n",
    "    clusters = gmm_utils.cluster_knn_louvain(data, neighbors = params['nb_neighbors'])\n",
    "#     ev = gmm_utils.externalValidation(y, clusters)\n",
    "#     iv = gmm_utils.internalValidation(dfOrig, clusters)\n",
    "\n",
    "#     params = {**params, **ev, **iv}\n",
    "    return params, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T19:42:00.315392Z",
     "start_time": "2018-12-24T19:41:59.475314Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T18:57:40.602123Z",
     "start_time": "2018-12-24T18:57:37.425664Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(df.shape, truth.shape, truth.clusters.unique())\n",
    "params={}\n",
    "params['dataset'] = 'brainCIDR'\n",
    "params['minCellsPerGene'] = 0\n",
    "params['minGeneDispersion'] = 0\n",
    "params['log'] = True # True, False\n",
    "params['scaler'] = 'standardScaleCells'# \n",
    "params['pca_comp'] = 10 #range (3, 300)\n",
    "params['doUmap'] = True #range (3, 300)\n",
    "params['umap_comp'] = 3\n",
    "params['nb_neighbors'] =10 #3 -15\n",
    "xx, clusters = runLouvain(params)\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T11:09:26.296486Z",
     "start_time": "2018-12-16T11:09:26.290614Z"
    }
   },
   "outputs": [],
   "source": [
    "method = 'louvain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T11:09:41.041643Z",
     "start_time": "2018-12-16T11:09:41.017074Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def runHyperopt(trialsFile, resultsFile, space, max_evals = 2, restart = False):\n",
    "    # Define function to optimise\n",
    "    def evaluateLouvain(args):\n",
    "        try:\n",
    "            resultDict, _ = gmm_utils.runLouvain(args)\n",
    "            if os.path.isfile(resultsFile):\n",
    "                results = pd.read_pickle(resultsFile)\n",
    "\n",
    "                newDf = pd.DataFrame.from_dict(resultDict, orient='index').T\n",
    "                results = results.append(newDf)\n",
    "\n",
    "            else:\n",
    "\n",
    "                results = pd.DataFrame.from_dict(resultDict, orient='index').T\n",
    "            results.to_pickle(resultsFile)\n",
    "        except:\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "            return { 'status' : hyperopt.STATUS_FAIL}\n",
    "\n",
    "        print(f'>> Result: {resultDict[\"_rand_index\"]}')\n",
    "        ret = {\n",
    "            'loss' : -resultDict['_rand_index']\n",
    "            ,'status' : STATUS_OK\n",
    "            ,'eval_time' : time.time()        \n",
    "        }\n",
    "        return ret\n",
    "\n",
    "    trials = hyperopt_utils.getTrials(trialsFile ,restart = restart )\n",
    "    evals_per_epoch = 10\n",
    "    for e in range(len(trials), max_evals, evals_per_epoch):\n",
    "        best = fmin(evaluateLouvain\n",
    "                    ,space\n",
    "                    ,algo=tpe.suggest \n",
    "                    ,max_evals= e + evals_per_epoch\n",
    "                    ,trials=trials)\n",
    "        print('Index ', e)\n",
    "#         pickle.dump(trials, open(trialsFile, 'wb'))\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain CIDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T11:10:45.217890Z",
     "start_time": "2018-12-16T11:10:45.208268Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'brainCIDR'\n",
    "space = {\n",
    "    'dataset' : dataset\n",
    "    ,'minCellsPerGene':scope.int(hp.quniform('minCellsPerGene', 0, 5, 1))\n",
    "    ,'minGeneDispersion':hp.uniform('minGeneDispersion', 0, 1.5)\n",
    "    ,'log' : hp.choice('log', [True,False])\n",
    "    ,'scaler' : hp.choice('scaler',\n",
    "            ['none','standardScaleGenes', 'standardScaleCells', 'robustScaleGenes', 'robustScaleCells'])\n",
    "    ,'pca_comp' : scope.int(hp.quniform('pca_comp', 5, 300,1))\n",
    "    ,'doUmap' : hp.choice('doUmap', [True,False])\n",
    "    ,'umap_comp' : scope.int(hp.quniform('umap_comp', 2, 5,1))\n",
    "    ,'nb_neighbors' : scope.int(hp.quniform('nb_neighbors', 6, 30, 1))\n",
    "}\n",
    "\n",
    "trialsFile = f'data/{dataset}_{method}_trials.pkl'\n",
    "resultsFile = f'data/{dataset}_{method}_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T11:31:43.144852Z",
     "start_time": "2018-12-16T11:10:53.855321Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = runHyperopt(trialsFile, resultsFile, space, max_evals = 500, restart = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:26:49.170485Z",
     "start_time": "2018-12-09T12:26:48.849118Z"
    }
   },
   "outputs": [],
   "source": [
    "resultsDf = pd.read_pickle(resultsFile)\n",
    "display(resultsDf.sort_values(by='_rand_index', ascending = False).head(3))\n",
    "gmm_utils.plotCorrelation(resultsDf, name=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PancreaticIsletCIDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:27:03.136192Z",
     "start_time": "2018-12-09T12:27:02.657860Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset= 'pancreaticIsletCIDR'\n",
    "df, truth = gmm_utils.loadData(dataset)\n",
    "print(df.shape, truth.shape, truth.clusters.unique())\n",
    "trialsFile = f'data/{dataset}_{method}_trials.pkl'\n",
    "resultsFile = f'data/{dataset}_{method}_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space = {\n",
    "    'dataset' : dataset\n",
    "    ,'minCellsPerGene':scope.int(hp.quniform('minCellsPerGene', 0, 5, 1))\n",
    "    ,'minGeneDispersion':hp.uniform('minGeneDispersion', 0, 1.5)\n",
    "    ,'log' : hp.choice('log', [True,False])\n",
    "    ,'scaler' : hp.choice('scaler',\n",
    "            ['none','standardScaleGenes', 'standardScaleCells', 'robustScaleGenes', 'robustScaleCells'])\n",
    "    ,'pca_comp' : scope.int(hp.quniform('pca_comp', 5, 300,1))\n",
    "    ,'doUmap' : hp.choice('doUmap', [True,False])\n",
    "    ,'umap_comp' : scope.int(hp.quniform('umap_comp', 2, 5,1))\n",
    "    ,'nb_neighbors' : scope.int(hp.quniform('nb_neighbors', 6, 30, 1))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials=hyperopt_utils.getTrials(filename ,restart = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = runHyperopt(trialsFile, resultsFile, space, max_evals = 500, restart = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:27:09.567428Z",
     "start_time": "2018-12-09T12:27:09.243871Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "resultsDf = pd.read_pickle(resultsFile)\n",
    "display(resultsDf.sort_values(by='_rand_index', ascending = False).head(3))\n",
    "gmm_utils.plotCorrelation(resultsDf, name=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:28:04.863027Z",
     "start_time": "2018-12-09T12:28:04.518721Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset= 'deng'\n",
    "df, truth = gmm_utils.loadData(dataset)\n",
    "print(df.shape, truth.shape, truth.clusters.unique())\n",
    "trialsFile = f'data/{dataset}_{method}_trials.pkl'\n",
    "resultsFile = f'data/{dataset}_{method}_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:29:41.682049Z",
     "start_time": "2018-12-09T12:29:41.677095Z"
    }
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'dataset' : dataset\n",
    "    ,'minCellsPerGene':scope.int(hp.quniform('minCellsPerGene', 0, 5, 1))\n",
    "    ,'minGeneDispersion':hp.uniform('minGeneDispersion', 0, 1.5)\n",
    "    ,'log' : hp.choice('log', [True,False])\n",
    "    ,'scaler' : hp.choice('scaler',\n",
    "            ['none','standardScaleGenes', 'standardScaleCells', 'robustScaleGenes', 'robustScaleCells'])\n",
    "    ,'pca_comp' : scope.int(hp.quniform('pca_comp', 5, 200,1))\n",
    "    ,'doUmap' : hp.choice('doUmap', [True,False])\n",
    "    ,'umap_comp' : scope.int(hp.quniform('umap_comp', 2, 5,1))\n",
    "    ,'nb_neighbors' : scope.int(hp.quniform('nb_neighbors', 6, 30, 1))\n",
    "}\n",
    "trials = runHyperopt(trialsFile, resultsFile, space, max_evals = 500, restart = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:41:43.987257Z",
     "start_time": "2018-12-09T12:41:43.663095Z"
    }
   },
   "outputs": [],
   "source": [
    "resultsDf = pd.read_pickle(resultsFile)\n",
    "display(resultsDf.sort_values(by='_rand_index', ascending = False).head(3))\n",
    "utils.plotCorrelation(resultsDf, name=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sce10x_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:20:26.024384Z",
     "start_time": "2018-12-15T13:20:25.785025Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset= 'sce10x_qc'\n",
    "df, truth = utils.loadData(dataset)\n",
    "print(df.shape, truth.shape, truth.clusters.unique())\n",
    "trialsFile = f'data/{dataset}_{method}_trials.pkl'\n",
    "resultsFile = f'data/{dataset}_{method}_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:51:06.224475Z",
     "start_time": "2018-12-15T13:20:32.811332Z"
    }
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'dataset' : dataset\n",
    "    ,'minCellsPerGene':scope.int(hp.quniform('minCellsPerGene', 0, 5, 1))\n",
    "    ,'minGeneDispersion':hp.uniform('minGeneDispersion', 0, 1.5)\n",
    "    ,'log' : hp.choice('log', [True,False])\n",
    "    ,'scaler' : hp.choice('scaler',\n",
    "            ['none','standardScaleGenes', 'standardScaleCells', 'robustScaleGenes', 'robustScaleCells'])\n",
    "    ,'pca_comp' : scope.int(hp.quniform('pca_comp', 5, 200,1))\n",
    "    ,'doUmap' : hp.choice('doUmap', [True,False])\n",
    "    ,'umap_comp' : scope.int(hp.quniform('umap_comp', 2, 5,1))\n",
    "    ,'nb_neighbors' : scope.int(hp.quniform('nb_neighbors', 6, 30, 1))\n",
    "}\n",
    "trials = runHyperopt(trialsFile, resultsFile, space, max_evals = 500, restart = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:51:55.669654Z",
     "start_time": "2018-12-15T13:51:55.346132Z"
    }
   },
   "outputs": [],
   "source": [
    "resultsDf = pd.read_pickle(resultsFile)\n",
    "display(resultsDf.sort_values(by='_rand_index', ascending = False).head(3))\n",
    "utils.plotCorrelation(resultsDf, name=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sce2_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:52:10.630866Z",
     "start_time": "2018-12-15T13:52:10.551184Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset= 'sce2_qc'\n",
    "df, truth = utils.loadData(dataset)\n",
    "print(df.shape, truth.shape, truth.clusters.unique())\n",
    "trialsFile = f'data/{dataset}_{method}_trials.pkl'\n",
    "resultsFile = f'data/{dataset}_{method}_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T14:05:17.827669Z",
     "start_time": "2018-12-15T13:52:13.907388Z"
    }
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'dataset' : dataset\n",
    "    ,'minCellsPerGene':scope.int(hp.quniform('minCellsPerGene', 0, 5, 1))\n",
    "    ,'minGeneDispersion':hp.uniform('minGeneDispersion', 0, 1.5)\n",
    "    ,'log' : hp.choice('log', [True,False])\n",
    "    ,'scaler' : hp.choice('scaler',\n",
    "            ['none','standardScaleGenes', 'standardScaleCells', 'robustScaleGenes', 'robustScaleCells'])\n",
    "    ,'pca_comp' : scope.int(hp.quniform('pca_comp', 5, 200,1))\n",
    "    ,'doUmap' : hp.choice('doUmap', [True,False])\n",
    "    ,'umap_comp' : scope.int(hp.quniform('umap_comp', 2, 5,1))\n",
    "    ,'nb_neighbors' : scope.int(hp.quniform('nb_neighbors', 6, 30, 1))\n",
    "}\n",
    "trials = runHyperopt(trialsFile, resultsFile, space, max_evals = 500, restart = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T14:05:41.948094Z",
     "start_time": "2018-12-15T14:05:41.629082Z"
    }
   },
   "outputs": [],
   "source": [
    "resultsDf = pd.read_pickle(resultsFile)\n",
    "display(resultsDf.sort_values(by='_rand_index', ascending = False).head(3))\n",
    "utils.plotCorrelation(resultsDf, name=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sce8_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T14:05:48.234223Z",
     "start_time": "2018-12-15T14:05:48.165300Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset= 'sce8_qc'\n",
    "df, truth = utils.loadData(dataset)\n",
    "print(df.shape, truth.shape, truth.clusters.unique())\n",
    "trialsFile = f'data/{dataset}_{method}_trials.pkl'\n",
    "resultsFile = f'data/{dataset}_{method}_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T14:27:00.405478Z",
     "start_time": "2018-12-15T14:05:49.989047Z"
    }
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'dataset' : dataset\n",
    "    ,'minCellsPerGene':scope.int(hp.quniform('minCellsPerGene', 0, 5, 1))\n",
    "    ,'minGeneDispersion':hp.uniform('minGeneDispersion', 0, 1.5)\n",
    "    ,'log' : hp.choice('log', [True,False])\n",
    "    ,'scaler' : hp.choice('scaler',\n",
    "            ['none','standardScaleGenes', 'standardScaleCells', 'robustScaleGenes', 'robustScaleCells'])\n",
    "    ,'pca_comp' : scope.int(hp.quniform('pca_comp', 5, 200,1))\n",
    "    ,'doUmap' : hp.choice('doUmap', [True,False])\n",
    "    ,'umap_comp' : scope.int(hp.quniform('umap_comp', 2, 5,1))\n",
    "    ,'nb_neighbors' : scope.int(hp.quniform('nb_neighbors', 6, 30, 1))\n",
    "}\n",
    "trials = runHyperopt(trialsFile, resultsFile, space, max_evals = 500, restart = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDf = pd.read_pickle(resultsFile)\n",
    "display(resultsDf.sort_values(by='_rand_index', ascending = False).head(3))\n",
    "utils.plotCorrelation(resultsDf, name=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestBic, bestAic, bestSil = optimalNbClustersGMM(pc, params['min_clusters'], params['max_clusters'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestBic, bestAic, bestSil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_clust in n_clusters:\n",
    "    model = GaussianMixture(n_clust, covariance_type ='full', random_state = 0).fit(pc)\n",
    "    clusters = model.predict(pc)\n",
    "    score = adjusted_rand_score(truth.clusters.tolist(), clusters)\n",
    "    print(f\"For {n_clust} clusters, score : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianMixture(8, covariance_type ='full', random_state = 0).fit(pc)\n",
    "clusters = model.predict(pc)\n",
    "score = adjusted_rand_score(truth.clusters.tolist(), clusters)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth.clusters.value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'brainCIDR'\n",
    "df, truth = gmm_utils.loadData(dataset)\n",
    "umap2D = gmm_utils.getUmap(df, pca_comp = 10)\n",
    "print(df.shape, truth.shape, truth.clusters.unique())\n",
    "params={}\n",
    "params['dataset'] = 'brainCIDR'\n",
    "params['minCellsPerGene'] = 0\n",
    "params['minGeneDispersion'] = 0\n",
    "params['log'] = True # True, False\n",
    "params['scaler'] = 'standardScaleCells'# \n",
    "params['pca_comp'] = 10 #range (3, 300)\n",
    "params['nb_clusters'] =8 #3 -15\n",
    "gmm_utils.run(params);"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
